{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9acfe5b",
   "metadata": {},
   "source": [
    "# Task 0 (Try 2): Story-Level Generation\n",
    "\n",
    "**Problem:** The paragraph-level approach in Try 1 made the AI text too easy to detect. The explicit structural constraints and lens-based prompts created predictable patterns in punctuation density, sentence rhythm, and readability metrics.\n",
    "\n",
    "**Solution:** Generate longer continuous narratives (1,500-3,000 words) and segment them naturally into paragraphs afterward. This allows organic variation in:\n",
    "- Sentence length and rhythm\n",
    "- Punctuation patterns  \n",
    "- Stylistic drift across paragraphs\n",
    "- Topic emergence through narrative flow\n",
    "\n",
    "This notebook generates Classes 2 and 3 using the story-level approach. Class 1 remains the same human text from Project Gutenberg.\n",
    "\n",
    "**Output files:**\n",
    "- `class2_ai_story_paragraphs_try2.json` - 500 AI-generated paragraphs (neutral style, story-based)\n",
    "- `class3_ai_story_paragraphs_try2.json` - 500 AI-generated paragraphs (author-styled, story-based)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb65cfbc",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "All dependencies consolidated in one place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3af029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "import re\n",
    "import hashlib\n",
    "import random\n",
    "from itertools import product\n",
    "from google import genai\n",
    "\n",
    "\n",
    "# API key from environmentos.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyC-yEM1oYrnRGRl31LhO1jUVPksDadQBk0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc04e02",
   "metadata": {},
   "source": [
    "## API Configuration\n",
    "\n",
    "Again using Gemini's gemma-3-27b-it model via Google's GenAI API as it has a free tier for experimentation. Works well for fiction generation without needing paid API access.\n",
    "\n",
    "**Temperature:** Using higher diversity settings (temp=1.0, top_p=0.99) to encourage natural variation in story flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d83e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "MODEL_NAME = \"models/gemma-3-27b-it\"\n",
    "\n",
    "def call_gemma_api(prompt, temperature=1):\n",
    "    \"\"\"Call Gemma API with retry logic and high diversity settings.\"\"\"\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model=MODEL_NAME,\n",
    "            contents=prompt,\n",
    "            config={\n",
    "                \"temperature\": temperature,\n",
    "                \"top_p\": 0.99,\n",
    "                \"top_k\": 50,\n",
    "                \"max_output_tokens\": 3500\n",
    "            }\n",
    "        )\n",
    "        return response.text.strip()\n",
    "    except Exception as e:\n",
    "        print(\"API error:\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcba7d4",
   "metadata": {},
   "source": [
    "## Thematic Anchors\n",
    "\n",
    "Using the same 9 corpus-level topics extracted from Austen + Gaskell novels as in try-1. As said before, these aren't per-book topics but themes that span the entire literary corpus. They provide narrative direction without over-constraining the generation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e114e957",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [\n",
    "    \"Courtship and Marriage\",\n",
    "    \"Domestic Life and Family Obligation\",\n",
    "    \"Social Class and Reputation\",\n",
    "    \"Moral Judgment and Personal Character\",\n",
    "    \"Gender Roles and Social Constraint\",\n",
    "    \"Work, Industry, and Economic Struggle\",\n",
    "    \"Community, Gossip, and Social Networks\",\n",
    "    \"Individual Desire versus Social Expectation\",\n",
    "    \"Change, Mobility, and Social Reform\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c98d1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTHORS = [\"austen\", \"gaskell\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d33a76",
   "metadata": {},
   "source": [
    "## Author Style Guides (Class 3 Only)\n",
    "\n",
    "For Class 3, we provide stylistic guides the same way as try1 to mimic Austen or Gaskell's narrative voice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2221edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTHOR_STYLE_GUIDES = {\n",
    "    \"austen\": \"\"\"\n",
    "- Use syntactically complex but balanced sentences\n",
    "- Employ indirect evaluation and mild irony\n",
    "- Prefer formal, polite diction\n",
    "- Embed moral judgment subtly within narration\n",
    "- Avoid emotional excess or overt sentiment\n",
    "\"\"\",\n",
    "    \"gaskell\": \"\"\"\n",
    "- Use emotionally expressive but controlled language\n",
    "- Emphasize social conditions and human impact\n",
    "- Allow moral concern to be explicit\n",
    "- Alternate between reflection and description\n",
    "- Use grounded, socially aware narration\n",
    "\"\"\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da6516e",
   "metadata": {},
   "source": [
    "## Segmentation Function\n",
    "\n",
    "After generating a long story, we split it into 100-200 word chunks. The split points are random within that range, creating natural variation in paragraph length (unlike Try 1's uniform chunks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178f4679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_story(text, min_words=100, max_words=200):\n",
    "    words = text.split()\n",
    "    paras = []\n",
    "    i = 0\n",
    "    while i < len(words):\n",
    "        size = random.randint(min_words, max_words)\n",
    "        chunk = words[i:i+size]\n",
    "        if len(chunk) >= min_words:\n",
    "            paras.append(\" \".join(chunk))\n",
    "        i += size\n",
    "    return paras\n",
    "\n",
    "\n",
    "def normalize_hash(text): \n",
    "    text = text.lower()    \n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return hashlib.md5(text.strip().encode()).hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0df8ee4",
   "metadata": {},
   "source": [
    "## Class 2: Neutral AI Stories\n",
    "\n",
    "Prompt structure:\n",
    "- Randomly sample 3 topics from the 9 available\n",
    "- Request 2,000-2,500 word continuous narrative\n",
    "- No explicit structural constraints (unlike Try 1's lens + constraint system)\n",
    "- Variation ID included for prompt diversity (Gemma is deterministic otherwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db337fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_class2_story_prompt(topic):\n",
    "    vid = uuid.uuid4().hex[:8]\n",
    "    return f\"\"\"\n",
    "Topic:\n",
    "\"{topic}\"\n",
    "\n",
    "Task:\n",
    "Write a continuous fictional narrative of approximately 2,000-2,500 words.\n",
    "\n",
    "Guidelines:\n",
    "- Neutral voice\n",
    "- Do NOT imitate any author\n",
    "- Allow natural variation in sentence length and punctuation\n",
    "- Avoid structured exposition or list-like explanations\n",
    "- Let the topic emerge organically through events or reflection\n",
    "\n",
    "Rules:\n",
    "- No explicit summaries\n",
    "- No references to real novels or characters\n",
    "- No need to maintain strict structure\n",
    "\n",
    "Variation ID: {vid}\n",
    "\n",
    "Return only the story text.\n",
    "\"\"\".strip(), vid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434f153c",
   "metadata": {},
   "source": [
    "## Generate Class 2 Dataset\n",
    "\n",
    "Strategy:\n",
    "1. Generate long stories (not individual paragraphs)\n",
    "2. Segment each story into 100-200 word chunks\n",
    "3. Deduplicate using first 500 characters as key\n",
    "4. Collect until we have 500 paragraphs\n",
    "\n",
    "Each story produces multiple paragraphs, so we need fewer API calls than Try 1 (which generated 500 separate paragraphs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cee45be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story 1: added 10 paragraphs (total: 10/500)\n",
      "Story 2: added 9 paragraphs (total: 19/500)\n",
      "Story 3: added 9 paragraphs (total: 28/500)\n",
      "Story 4: added 11 paragraphs (total: 39/500)\n",
      "Story 5: added 11 paragraphs (total: 50/500)\n",
      "Story 6: added 10 paragraphs (total: 60/500)\n",
      "Story 7: added 9 paragraphs (total: 69/500)\n",
      "Story 8: added 10 paragraphs (total: 79/500)\n",
      "Story 9: added 9 paragraphs (total: 88/500)\n",
      "Story 10: added 10 paragraphs (total: 98/500)\n",
      "API error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
      "Story 11: added 10 paragraphs (total: 108/500)\n",
      "Story 12: added 10 paragraphs (total: 118/500)\n",
      "Story 13: added 11 paragraphs (total: 129/500)\n",
      "Story 14: added 10 paragraphs (total: 139/500)\n",
      "API error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
      "Story 15: added 10 paragraphs (total: 149/500)\n",
      "Story 16: added 11 paragraphs (total: 160/500)\n",
      "Story 17: added 11 paragraphs (total: 171/500)\n",
      "Story 18: added 11 paragraphs (total: 182/500)\n",
      "Story 19: added 11 paragraphs (total: 193/500)\n",
      "Story 20: added 9 paragraphs (total: 202/500)\n",
      "Story 21: added 9 paragraphs (total: 211/500)\n",
      "Story 22: added 10 paragraphs (total: 221/500)\n",
      "Story 23: added 9 paragraphs (total: 230/500)\n",
      "Story 24: added 10 paragraphs (total: 240/500)\n",
      "Story 25: added 9 paragraphs (total: 249/500)\n",
      "Story 26: added 11 paragraphs (total: 260/500)\n",
      "Story 27: added 11 paragraphs (total: 271/500)\n",
      "Story 28: added 9 paragraphs (total: 280/500)\n",
      "Story 29: added 10 paragraphs (total: 290/500)\n",
      "Story 30: added 9 paragraphs (total: 299/500)\n",
      "Story 31: added 9 paragraphs (total: 308/500)\n",
      "Story 32: added 11 paragraphs (total: 319/500)\n",
      "Story 33: added 10 paragraphs (total: 329/500)\n",
      "Story 34: added 9 paragraphs (total: 338/500)\n",
      "Story 35: added 10 paragraphs (total: 348/500)\n",
      "Story 36: added 9 paragraphs (total: 357/500)\n",
      "Story 37: added 11 paragraphs (total: 368/500)\n",
      "Story 38: added 9 paragraphs (total: 377/500)\n",
      "Story 39: added 9 paragraphs (total: 386/500)\n",
      "Story 40: added 10 paragraphs (total: 396/500)\n",
      "Story 41: added 9 paragraphs (total: 405/500)\n",
      "Story 42: added 10 paragraphs (total: 415/500)\n",
      "Story 43: added 10 paragraphs (total: 425/500)\n",
      "Story 44: added 10 paragraphs (total: 435/500)\n",
      "Story 45: added 10 paragraphs (total: 445/500)\n",
      "Story 46: added 9 paragraphs (total: 454/500)\n",
      "Story 47: added 10 paragraphs (total: 464/500)\n",
      "Story 48: added 9 paragraphs (total: 473/500)\n",
      "Story 49: added 9 paragraphs (total: 482/500)\n",
      "Story 50: added 10 paragraphs (total: 492/500)\n",
      "Story 51: added 8 paragraphs (total: 500/500)\n",
      "\n",
      "Class 2 story dataset complete: 500 paragraphs\n"
     ]
    }
   ],
   "source": [
    "class2_story_paragraphs = []\n",
    "seen = set()\n",
    "story_count = 0\n",
    "\n",
    "while len(class2_story_paragraphs) < 500:\n",
    "    topic = random.sample(topics, k=3)\n",
    "    prompt, vid = build_class2_story_prompt(topic)\n",
    "    story = call_gemma_api(prompt)\n",
    "\n",
    "    if not story:\n",
    "        continue\n",
    "\n",
    "    story_count += 1\n",
    "    paras = segment_story(story)\n",
    "\n",
    "    added = 0\n",
    "    for p in paras:\n",
    "        if len(class2_story_paragraphs) >= 500:\n",
    "            break\n",
    "\n",
    "        # Validate word count\n",
    "        word_count = len(p.split())\n",
    "        if word_count < 100 or word_count > 200:\n",
    "            continue\n",
    "\n",
    "        # MD5 hash for robust deduplication\n",
    "        key = normalize_hash(p)\n",
    "        if key in seen:\n",
    "            continue\n",
    "\n",
    "        seen.add(key)\n",
    "        class2_story_paragraphs.append({\n",
    "            \"text\": p,\n",
    "            \"label\": \"ai\",\n",
    "            \"variant\": \"story\",\n",
    "            \"topic\": topic,\n",
    "            \"variation_id\": vid\n",
    "        })\n",
    "        added += 1\n",
    "\n",
    "    print(f\"Story {story_count}: added {added} paragraphs (total: {len(class2_story_paragraphs)}/500)\")\n",
    "    time.sleep(1.0)\n",
    "\n",
    "print(f\"\\nClass 2 story dataset complete: {len(class2_story_paragraphs)} paragraphs\")\n",
    "\n",
    "with open(\"class2_ai_story_paragraphs_try2.json\", \"w\") as f:\n",
    "    json.dump(class2_story_paragraphs, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c6a7f7",
   "metadata": {},
   "source": [
    "## Class 3: Author-Styled AI Stories\n",
    "\n",
    "Similar to Class 2 but with:\n",
    "- Author style guidance (Austen or Gaskell tendencies)\n",
    "- Same story-level generation approach\n",
    "- Topic subsets for narrative direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a8b8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_class3_story_prompt(topics, author):\n",
    "    vid = uuid.uuid4().hex[:8]\n",
    "    style_guide = AUTHOR_STYLE_GUIDES[author]\n",
    "\n",
    "    topic_block = \"\\n\".join(f\"- {t}\" for t in topics)\n",
    "\n",
    "    return f\"\"\"\n",
    "Write a continuous fictional narrative of approximately 2,000-2,500 words.\n",
    "\n",
    "The story should naturally engage with the following themes:\n",
    "{topic_block}\n",
    "\n",
    "Write in a style inspired by {author.title()}, following these tendencies:\n",
    "{style_guide}\n",
    "\n",
    "Guidelines:\n",
    "- Maintain a consistent narrative voice shaped by the authorâ€™s style\n",
    "- Allow natural variation in sentence length, rhythm, and punctuation\n",
    "- Let themes emerge organically through character experience\n",
    "- Accept minor stylistic unevenness, as in real long-form prose\n",
    "\n",
    "Rules:\n",
    "- Do NOT reference specific novels, characters, or places\n",
    "- Do NOT quote or paraphrase existing text\n",
    "- Avoid modern slang or anachronisms\n",
    "- No explicit summaries or sectioning\n",
    "\n",
    "Return only the story text.\n",
    "\"\"\".strip(), vid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d51b85",
   "metadata": {},
   "source": [
    "## Generate Class 3 Dataset\n",
    "\n",
    "Same process as Class 2:\n",
    "1. Generate styled stories with author guidance\n",
    "2. Segment naturally into paragraphs\n",
    "3. Deduplicate and collect 500 paragraphs\n",
    "\n",
    "The continuous narrative approach should produce more human-like artifacts than Try 1's structured paragraph generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f9eef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story 1 (gaskell): added 10 paragraphs (total: 10/500)\n",
      "Story 2 (gaskell): added 9 paragraphs (total: 19/500)\n",
      "Story 3 (austen): added 11 paragraphs (total: 30/500)\n",
      "Story 4 (gaskell): added 10 paragraphs (total: 40/500)\n",
      "Story 5 (austen): added 11 paragraphs (total: 51/500)\n",
      "API error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
      "Story 6 (austen): added 10 paragraphs (total: 61/500)\n",
      "Story 7 (austen): added 9 paragraphs (total: 70/500)\n",
      "Story 8 (gaskell): added 9 paragraphs (total: 79/500)\n",
      "Story 9 (gaskell): added 9 paragraphs (total: 88/500)\n",
      "Story 10 (austen): added 9 paragraphs (total: 97/500)\n",
      "Story 11 (austen): added 10 paragraphs (total: 107/500)\n",
      "Story 12 (austen): added 9 paragraphs (total: 116/500)\n",
      "Story 13 (austen): added 9 paragraphs (total: 125/500)\n",
      "Story 14 (austen): added 9 paragraphs (total: 134/500)\n",
      "Story 15 (gaskell): added 9 paragraphs (total: 143/500)\n",
      "API error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
      "Story 16 (gaskell): added 10 paragraphs (total: 153/500)\n",
      "Story 17 (austen): added 10 paragraphs (total: 163/500)\n",
      "Story 18 (gaskell): added 11 paragraphs (total: 174/500)\n",
      "API error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
      "API error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
      "Story 19 (gaskell): added 8 paragraphs (total: 182/500)\n",
      "Story 20 (austen): added 9 paragraphs (total: 191/500)\n",
      "Story 21 (gaskell): added 9 paragraphs (total: 200/500)\n",
      "Story 22 (austen): added 10 paragraphs (total: 210/500)\n",
      "API error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
      "Story 23 (gaskell): added 9 paragraphs (total: 219/500)\n",
      "Story 24 (austen): added 12 paragraphs (total: 231/500)\n",
      "Story 25 (gaskell): added 9 paragraphs (total: 240/500)\n",
      "Story 26 (gaskell): added 10 paragraphs (total: 250/500)\n",
      "Story 27 (austen): added 10 paragraphs (total: 260/500)\n",
      "Story 28 (gaskell): added 9 paragraphs (total: 269/500)\n",
      "Story 29 (austen): added 10 paragraphs (total: 279/500)\n",
      "API error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
      "API error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
      "Story 30 (austen): added 9 paragraphs (total: 288/500)\n",
      "Story 31 (austen): added 11 paragraphs (total: 299/500)\n",
      "Story 32 (gaskell): added 10 paragraphs (total: 309/500)\n",
      "Story 33 (gaskell): added 8 paragraphs (total: 317/500)\n",
      "API error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
      "Story 34 (gaskell): added 10 paragraphs (total: 327/500)\n",
      "API error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
      "API error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
      "Story 35 (gaskell): added 9 paragraphs (total: 336/500)\n",
      "Story 36 (austen): added 10 paragraphs (total: 346/500)\n",
      "Story 37 (gaskell): added 10 paragraphs (total: 356/500)\n",
      "Story 38 (austen): added 10 paragraphs (total: 366/500)\n",
      "Story 39 (gaskell): added 10 paragraphs (total: 376/500)\n",
      "Story 40 (gaskell): added 10 paragraphs (total: 386/500)\n",
      "API error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
      "API error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
      "API error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
      "Story 41 (austen): added 10 paragraphs (total: 396/500)\n",
      "Story 42 (gaskell): added 11 paragraphs (total: 407/500)\n",
      "API error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
      "Story 43 (gaskell): added 9 paragraphs (total: 416/500)\n",
      "Story 44 (gaskell): added 10 paragraphs (total: 426/500)\n",
      "API error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
      "Story 45 (austen): added 11 paragraphs (total: 437/500)\n",
      "Story 46 (gaskell): added 10 paragraphs (total: 447/500)\n",
      "Story 47 (gaskell): added 10 paragraphs (total: 457/500)\n",
      "Story 48 (austen): added 9 paragraphs (total: 466/500)\n",
      "Story 49 (gaskell): added 9 paragraphs (total: 475/500)\n",
      "Story 50 (austen): added 8 paragraphs (total: 483/500)\n",
      "Story 51 (gaskell): added 9 paragraphs (total: 492/500)\n",
      "Story 52 (gaskell): added 8 paragraphs (total: 500/500)\n",
      "\n",
      "Class 3 story dataset complete: 500 paragraphs\n"
     ]
    }
   ],
   "source": [
    "class3_story_paragraphs = []\n",
    "seen = set()\n",
    "story_count = 0\n",
    "\n",
    "TARGET_PARAS = 500\n",
    "AUTHORS = list(AUTHOR_STYLE_GUIDES.keys())\n",
    "\n",
    "while len(class3_story_paragraphs) < TARGET_PARAS:\n",
    "    author = random.choice(AUTHORS)\n",
    "    topic_subset = random.sample(topics, k=3)\n",
    "\n",
    "    prompt, vid = build_class3_story_prompt(\n",
    "        topics=topic_subset,\n",
    "        author=author\n",
    "    )\n",
    "\n",
    "    story = call_gemma_api(prompt, temperature=1.0)\n",
    "\n",
    "    if not story:\n",
    "        continue\n",
    "\n",
    "    story_count += 1\n",
    "    paras = segment_story(story)\n",
    "\n",
    "    added = 0\n",
    "    for p in paras:\n",
    "        if len(class3_story_paragraphs) >= TARGET_PARAS:\n",
    "            break\n",
    "\n",
    "        # Validate word count\n",
    "        word_count = len(p.split())\n",
    "        if word_count < 100 or word_count > 200:\n",
    "            continue\n",
    "\n",
    "        # MD5 hash for robust deduplication\n",
    "        key = normalize_hash(p)\n",
    "        if key in seen:\n",
    "            continue\n",
    "\n",
    "        seen.add(key)\n",
    "        class3_story_paragraphs.append({\n",
    "            \"text\": p,\n",
    "            \"label\": \"ai\",\n",
    "            \"variant\": \"story\",\n",
    "            \"author_style\": author,\n",
    "            \"topics\": topic_subset,\n",
    "            \"variation_id\": vid\n",
    "        })\n",
    "        added += 1\n",
    "\n",
    "    print(f\"Story {story_count} ({author}): added {added} paragraphs (total: {len(class3_story_paragraphs)}/{TARGET_PARAS})\")\n",
    "\n",
    "    with open(\"class3_ai_story_paragraphs_try2.json\", \"w\") as f:\n",
    "\n",
    "        json.dump(class3_story_paragraphs, f, indent=2)print(f\"\\nClass 3 story dataset complete: {len(class3_story_paragraphs)} paragraphs\")\n",
    "\n",
    "\n",
    "    time.sleep(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078e77b4",
   "metadata": {},
   "source": [
    "## Done\n",
    "\n",
    "Generated two AI datasets using story-level generation:\n",
    "- `class2_ai_story_paragraphs_try2.json`: 500 AI paragraphs (neutral)\n",
    "- `class3_ai_story_paragraphs_try2.json`: 500 AI paragraphs (styled)\n",
    "\n",
    "Class 1 remains the same human text from Try 1. The key difference is generation granularity: stories instead of paragraphs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e39acfa",
   "metadata": {},
   "source": [
    "### Dataset Summary\n",
    "\n",
    "**Class 1 (Human):**\n",
    "- Same as Try 1: 6 novels (3 Austen + 3 Gaskell)\n",
    "- Processing: HTML cleaning, boilerplate removal, re-chunking\n",
    "- Output: ~4000+ paragraphs, 100-200 words each\n",
    "\n",
    "**Class 2 (AI-Neutral):**\n",
    "- Source: Gemini API (gemma-3-27b-it)\n",
    "- Strategy: Story-level generation (1.5-3k words) then segmentation\n",
    "- Output: 500 paragraphs, 100-200 words each\n",
    "\n",
    "**Class 3 (AI-Styled):**\n",
    "- Source: Gemini API (gemma-3-27b-it)\n",
    "- Strategy: Story-level with author guidance, then segmentation\n",
    "- Output: 500 paragraphs, 100-200 words each\n",
    "\n",
    "The continuous narrative approach should produce more human-like variation than Try 1's paragraph-level constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0993b8",
   "metadata": {},
   "source": [
    "### Why This Matters\n",
    "\n",
    "Try 2 addresses a key limitation of Try 1: the paragraph-level generation with explicit structural constraints made AI text too easy to detect. By generating longer narratives and segmenting naturally:\n",
    "- Sentence rhythm varies organically\n",
    "- Punctuation patterns emerge naturally\n",
    "- Stylistic drift occurs across paragraphs (like real writing)\n",
    "\n",
    "In Task 2, we'll compare detectability across try1, try2, and try3 to see which generation strategy is most human-like."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813f1700",
   "metadata": {},
   "source": [
    "### Next: Try 3 - Few-Shot Style Mimicry\n",
    "\n",
    "**Limitation of Try 2:**\n",
    "While story-level generation creates more natural flow than Try 1's isolated paragraphs, the style guidance is still abstract (e.g., \"use complex sentences,\" \"employ irony\"). The model interprets these guidelines based on its training, which may not capture the **specific nuances** of Austen or Gaskell's actual prose.\n",
    "\n",
    "\n",
    "**Try 3 Approach:**\n",
    "Instead of abstract style guides, Try 3 will use **few-shot prompting with actual examples**:\n",
    "1. **Extract 3-5 representative paragraphs** from each author's novels (Class 1)\n",
    "2. **Show these as examples** in the prompt before generation\n",
    "3. **Generate stories** that mimic the demonstrated style more precisely\n",
    "4. **Extract paragraphs** as in Try 2\n",
    "\n",
    "**Why This Might Work Better:**\n",
    "- Model sees **concrete examples** of Austen/Gaskell's actual writing\n",
    "- Can capture **specific patterns**: sentence structure, word choice, punctuation habits\n",
    "- Mimics the \"in-context learning\" that makes LLMs good at style transfer\n",
    "- Should produce Class 3 text that's **harder to distinguish** from Class 1\n",
    "\n",
    "**Risk/Trade-off:**\n",
    "- **Direct phrase copying**: Model might paraphrase or repeat exact sentences from examples\n",
    "- **Template rigidity**: Outputs might follow the same structural pattern as examples\n",
    "- **Reduced diversity**: Strong anchoring might limit stylistic exploration beyond what examples demonstrate\n",
    "\n",
    "**Mitigation:**\n",
    "- Use examples from **different novels/chapters** to show style variety\n",
    "- Post-process similarity checks to detect direct copying\n",
    "- Use high temperature (1.0+) to encourage variation while maintaining style\n",
    "- Rotate different example sets across generations\n",
    "\n",
    "**Why topic leakage is NOT a concern:**\n",
    "- All classes already share the same 9 topics by design\n",
    "- Examples show HOW to write about those topics in the target style\n",
    "- The goal is learning style patterns, not introducing new content areas\n",
    "\n",
    "If Try 3 works, Class 3 should approach human-level stylistic authenticity. If it overfits, we'll see verbatim copying or mechanical template-following rather than genuine style transfer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_env)",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
