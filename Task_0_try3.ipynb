{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ab54d9f",
   "metadata": {},
   "source": [
    "# Task 0 (Try 3): Few-Shot Style Transfer\n",
    "\n",
    "**Problem:** Try 2's story-level generation improved naturalness, but style mimicry was still weak. The abstract style guides weren't enough to capture author-specific patterns. \n",
    "\n",
    "**Major Issue Identified:** Analysis of Try 1 and Try 2 outputs revealed that **punctuation patterns** were a key differentiator. AI text consistently showed different semicolon and em-dash usage compared to human text. This suggests punctuation is a crucial stylistic fingerprint that generic prompts fail to replicate.\n",
    "\n",
    "**Solution:** Add few-shot examples by extracting 3 random passages (60-120 words) from each author's actual work and including them in the prompt. This gives the model concrete examples of:\n",
    "- Sentence rhythm and structure\n",
    "- Characteristic vocabulary\n",
    "- **Punctuation habits** (semicolons, em-dashes, colons) (addressing the major weakness which was a differentiating factor between ai and human in Try 1/2)\n",
    "- Narrative voice\n",
    "\n",
    "The enhanced style guides now explicitly describe punctuation patterns for each author.\n",
    "\n",
    "Also increased temperature (1.3-1.4) and top_k (200-250) for more diversity.\n",
    "\n",
    "**Trade-off:** Risk of copying - we monitor this via deduplication. But the potential for better style mimicry is worth testing.\n",
    "\n",
    "**Output files:**\n",
    "- `class2_ai_story_paragraphs_try3.json` - 500 AI paragraphs (neutral, with improved prompting)\n",
    "- `class3_ai_story_paragraphs_try3.json` - 500 AI paragraphs (styled, with few-shot examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c73750",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "All dependencies consolidated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4cae6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import random\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "from google import genai\n",
    "\n",
    "# API key from environment\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyC-yEM1oYrnRGRl31LhO1jUVPksDadQBk0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e11b26",
   "metadata": {},
   "source": [
    "## Loading human data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e3d4703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4054 human paragraphs\n"
     ]
    }
   ],
   "source": [
    "# Load human data\n",
    "with open(\"class1_human_data.json\", \"r\") as f:\n",
    "    human_data = json.load(f)\n",
    "\n",
    "topics = [\n",
    "    \"Courtship and Marriage\",\n",
    "    \"Domestic Life and Family Obligation\",\n",
    "    \"Social Class and Reputation\",\n",
    "    \"Moral Judgment and Personal Character\",\n",
    "    \"Gender Roles and Social Constraint\",\n",
    "    \"Work, Industry, and Economic Struggle\",\n",
    "    \"Community, Gossip, and Social Networks\",\n",
    "    \"Individual Desire versus Social Expectation\",\n",
    "    \"Change, Mobility, and Social Reform\"\n",
    "]\n",
    "\n",
    "print(f\"Loaded {len(human_data)} human paragraphs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390f4f89",
   "metadata": {},
   "source": [
    "## Configuration and Helper Functions\n",
    "\n",
    "Using the same Gemma model but with:\n",
    "- **Higher temperature** (1.3-1.4 vs 1.0 in Try 2) for more diversity\n",
    "- **Wider sampling** (top_k 200-250 vs 50) to access rare/author-specific vocabulary\n",
    "- **Few-shot examples** extracted from human data for Class 3\n",
    "\n",
    "**Why Gemma?** Same as Try 1 and Try 2. Free API access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0d95395",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "MODEL_NAME = \"models/gemma-3-27b-it\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ba30f2",
   "metadata": {},
   "source": [
    "## Class 2 Prompt Builder (Neutral Style)\n",
    "\n",
    "Generates prompts for neutral AI stories without style mimicry. Uses 3 randomly selected topics and encourages natural variation in:\n",
    "- Sentence structure (long and short)\n",
    "- Punctuation patterns (em-dashes, semicolons)\n",
    "- Narrative pacing\n",
    "- Human-like imperfections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eba411bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_class2_story_prompt_improved(topics):\n",
    "    vid = uuid.uuid4().hex[:8]\n",
    "    selected_themes = random.sample(topics, k=min(3, len(topics)))\n",
    "    theme_block = \"\\n\".join(f\"- {t}\" for t in selected_themes)\n",
    "    \n",
    "    prompt = f\"\"\"Write a continuous fictional narrative of approximately 1,500-2,000 words.\n",
    "\n",
    "The story should naturally touch on these themes:\n",
    "{theme_block}\n",
    "\n",
    "Write as you would for a personal creative writing project. The narrative should:\n",
    "- Flow organically with varied pacing\n",
    "- Include dialogue, description, and reflection as needed\n",
    "- Use natural punctuation (em-dashes, semicolons, etc.) where appropriate\n",
    "- Have varied sentence structures—some long and winding, some short and punchy\n",
    "- Show human-like imperfections: occasional run-ons, comma splices if dramatic\n",
    "- Let the story unfold naturally without rigid structure\n",
    "\n",
    "The themes should emerge through character situations and conflicts, not be stated explicitly.\n",
    "\n",
    "Write just the story. No title, no preamble, no conclusion marker.\n",
    "\"\"\"\n",
    "    return prompt.strip(), vid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7638e0",
   "metadata": {},
   "source": [
    "## Few-Shot Example Extractor\n",
    "\n",
    "Extracts random passages (50-100 words) from human text to use as style examples in Class 3 prompts. Tries to get `num_passages` examples by:\n",
    "1. Filtering paragraphs by author\n",
    "2. Randomly selecting and truncating to target length\n",
    "3. Capitalizing first letter for clean presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "875e7fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author_passages(author, human_data, num_passages=3, min_words=50, max_words=100):\n",
    "    author_paragraphs = [p['text'] for p in human_data if p.get('author') == author]\n",
    "    \n",
    "    if not author_paragraphs:\n",
    "        return []\n",
    "    \n",
    "    passages = []\n",
    "    for _ in range(num_passages * 3):\n",
    "        if len(passages) >= num_passages:\n",
    "            break\n",
    "        \n",
    "        para = random.choice(author_paragraphs)\n",
    "        words = para.split()\n",
    "        \n",
    "        if len(words) < min_words:\n",
    "            continue\n",
    "        \n",
    "        if len(words) > max_words:\n",
    "            start_idx = random.randint(0, len(words) - max_words)\n",
    "            passage_words = words[start_idx:start_idx + max_words]\n",
    "        else:\n",
    "            passage_words = words[:max_words]\n",
    "        \n",
    "        passage = \" \".join(passage_words)\n",
    "        \n",
    "        if passage:\n",
    "            passage = passage[0].upper() + passage[1:] if len(passage) > 1 else passage.upper()\n",
    "            passages.append(passage)\n",
    "    \n",
    "    return passages[:num_passages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837678fc",
   "metadata": {},
   "source": [
    "## Class 3 Prompt Builder (Few-Shot Style Transfer)\n",
    "\n",
    "Creates prompts for styled stories by:\n",
    "1. Extracting 3 actual passages from the target author's work\n",
    "2. Including these as concrete examples in the prompt\n",
    "3. Providing enhanced style guidelines\n",
    "4. Instructing the model to mimic patterns without copying\n",
    "\n",
    "This is the key innovation of Try 3 - showing the model actual examples rather than abstract descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24a73e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_class3_story_prompt_improved(topics, author, human_data):\n",
    "    vid = uuid.uuid4().hex[:8]\n",
    "    passages = get_author_passages(author, human_data, num_passages=3, min_words=60, max_words=120)\n",
    "    selected_themes = random.sample(topics, k=min(3, len(topics)))\n",
    "    theme_block = \"\\n\".join(f\"- {t}\" for t in selected_themes)\n",
    "    \n",
    "    examples_text = \"\"\n",
    "    if passages:\n",
    "        examples_text = f\"EXAMPLE PASSAGES FROM {author.upper()}'S WORK:\\n\\n\"\n",
    "        for i, passage in enumerate(passages, 1):\n",
    "            examples_text += f\"Example {i}:\\n\\\"{passage}\\\"\\n\\n\"\n",
    "    \n",
    "    prompt = f\"\"\"You are writing a narrative in the authentic style of {author.title()}.\n",
    "\n",
    "{examples_text}\n",
    "\n",
    "Now write a NEW, ORIGINAL fictional narrative of approximately 1,500-2,000 words.\n",
    "\n",
    "The story should naturally explore these themes:\n",
    "{theme_block}\n",
    "\n",
    "STYLE GUIDE for {author.upper()}:\n",
    "{AUTHOR_STYLE_GUIDES_ENHANCED[author]}\n",
    "\n",
    "IMPORTANT INSTRUCTIONS:\n",
    "1. Write AS IF you ARE {author.Title()} writing a story\n",
    "2. Match their sentence structures, rhythms, and patterns (see examples above)\n",
    "3. Use their characteristic vocabulary and register\n",
    "4. Follow their punctuation habits\n",
    "5. Adopt their narrative perspective and tone\n",
    "6. Let themes emerge through character and situation\n",
    "\n",
    "DO NOT:\n",
    "- Copy or paraphrase the examples above\n",
    "- Reference specific characters, places, or plots from {author}'s actual works\n",
    "- Break character into modern internet-speak or contemporary slang\n",
    "\n",
    "Allow the story to develop organically with {author}'s characteristic style—including any stylistic inconsistencies, emotional tangents, or pacing variations that appear in their work.\n",
    "\n",
    "Write only the story. No title, no preamble, no explanation.\n",
    "\"\"\"\n",
    "    return prompt.strip(), vid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263c8435",
   "metadata": {},
   "source": [
    "## API Call Function\n",
    "\n",
    "Calls the Gemma API with higher diversity settings than Try 2:\n",
    "- **Neutral**: temp=1.3, top_k=200\n",
    "- **Styled**: temp=1.4, top_k=250 (widest sampling for rare/author-specific vocabulary)\n",
    "\n",
    "Includes retry logic and minimum word count validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f6b7b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gemma_api_story(prompt, generation_type=\"neutral\"):\n",
    "    if generation_type == \"styled\":\n",
    "        config = {\n",
    "            \"temperature\": 1.4,\n",
    "            \"top_p\": 0.98,\n",
    "            \"top_k\": 250,              # Very wide sampling for rare words\n",
    "            \"max_output_tokens\": 2500, # Longer for stories\n",
    "        }\n",
    "    else:\n",
    "        config = {\n",
    "            \"temperature\": 1.3,        # Still high but slightly controlled\n",
    "            \"top_p\": 0.96,\n",
    "            \"top_k\": 200,\n",
    "            \"max_output_tokens\": 2500,\n",
    "        }\n",
    "    \n",
    "    max_retries = 3\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.models.generate_content(\n",
    "                model=MODEL_NAME,\n",
    "                contents=prompt,\n",
    "                config=config\n",
    "            )\n",
    "            \n",
    "            text = response.text.strip()\n",
    "            \n",
    "            if len(text.split()) < 400:\n",
    "                raise ValueError(f\"Story too short ({len(text.split())} words)\")\n",
    "            \n",
    "            return text\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"API error (attempt {attempt+1}/{max_retries}): {e}\")\n",
    "            time.sleep(2 ** attempt)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471c85f7",
   "metadata": {},
   "source": [
    "## Story Segmentation Function\n",
    "\n",
    "Takes generated stories and splits them into 100-200 word paragraphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a83dc5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_story_improved(story_text):\n",
    "    lines = story_text.split('\\n')\n",
    "    lines = [l.strip() for l in lines if l.strip()]\n",
    "    \n",
    "    paragraphs = []\n",
    "    current_chunk = []\n",
    "    current_word_count = 0\n",
    "    \n",
    "    for line in lines:\n",
    "        words = line.split()\n",
    "        line_word_count = len(words)\n",
    "        \n",
    "        if current_word_count + line_word_count <= 200:\n",
    "            current_chunk.append(line)\n",
    "            current_word_count += line_word_count\n",
    "        else:\n",
    "            if current_word_count >= 100:\n",
    "                paragraphs.append(' '.join(current_chunk))\n",
    "            current_chunk = [line]\n",
    "            current_word_count = line_word_count\n",
    "    \n",
    "    if current_word_count >= 100:\n",
    "        paragraphs.append(' '.join(current_chunk))\n",
    "    \n",
    "    return paragraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0547b8",
   "metadata": {},
   "source": [
    "## Enhanced Style Guides\n",
    "\n",
    "Refined author-specific style descriptors for better mimicry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "820584b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTHOR_STYLE_GUIDES_ENHANCED = {\n",
    "    \"austen\": \"\"\"\n",
    "PROSE CHARACTERISTICS:\n",
    "- Periodic sentences with delayed predicates: \"That [subject], however [qualification], must [predicate]\"\n",
    "- Free indirect discourse: seamless blend of narrator and character thoughts\n",
    "- Balanced antithesis: \"It was not that X, but that Y\"\n",
    "- Ironic understatement using hedging: \"perhaps\", \"rather\", \"tolerably\", \"somewhat\"\n",
    "\n",
    "VOCABULARY & DICTION:\n",
    "- Moral precision: propriety, delicacy, consequence, rectitude, amiable, prudence\n",
    "- Social hierarchy: establishment, connexion, acquaintance, civility, condescension\n",
    "- Formal register with strategic informality in dialogue\n",
    "- Abstract nouns for emotional states: \"her disappointment\", \"his resentment\"\n",
    "\n",
    "PUNCTUATION PATTERNS:\n",
    "- Frequent semicolons linking related independent clauses\n",
    "- Em-dashes for ironic asides or parenthetical commentary (—)\n",
    "- Commas for balanced parallel phrases\n",
    "- Minimal exclamation marks (reserve for genuine surprise in dialogue)\n",
    "- Colons introducing explanations or lists\n",
    "\n",
    "NARRATIVE VOICE:\n",
    "- Omniscient but detached and amused\n",
    "- Moral judgment embedded in description, not stated\n",
    "- Character self-deception revealed through narration\n",
    "- Precision in social observation\n",
    "- Wit through juxtaposition and contrast\n",
    "\n",
    "SENTENCE RHYTHMS:\n",
    "- Varied length but tendency toward complex-compound structures\n",
    "- Subordinate clauses often precede main clause\n",
    "- Parallel constructions: \"not only...but also\", \"neither...nor\"\n",
    "- Inversion for emphasis: \"Such was the impression...\"\n",
    "\"\"\",\n",
    "    \n",
    "    \"gaskell\": \"\"\"\n",
    "PROSE CHARACTERISTICS:\n",
    "- Cumulative description: piling detail upon detail\n",
    "- Emotional crescendos: observation to sympathy to moral statement\n",
    "- Direct emotional language (less ironic than Austen)\n",
    "- Alternation between dialogue and narrative commentary\n",
    "\n",
    "VOCABULARY & DICTION:\n",
    "- Industrial/labor: toil, manufactory, workfolk, mill, wage, labour, master\n",
    "- Emotional directness: sorrow, pity, tender, harsh, suffering, anguish, grief\n",
    "- Social concern: poverty, injustice, sympathy, duty, obligation, charity, want\n",
    "- Domestic/physical detail: hearth, threshold, chamber, dwelling, kitchen, garret\n",
    "- Nature imagery tied to mood: \"bleak\", \"desolate\", \"cheerless\"\n",
    "\n",
    "PUNCTUATION PATTERNS:\n",
    "- Heavy comma use in descriptive accumulation\n",
    "- Colons introducing consequences or explanations\n",
    "- Em-dashes for emotional interruption or intensification\n",
    "- More frequent exclamation marks (emotional emphasis)\n",
    "- Semicolons less frequent than Austen\n",
    "\n",
    "NARRATIVE VOICE:\n",
    "- Sympathetic moral witness\n",
    "- Direct appeals to reader's compassion\n",
    "- Explicit social criticism\n",
    "- Detailed environmental description (settings as character)\n",
    "- Emotional engagement rather than detachment\n",
    "SENTENCE RHYTHMS:\n",
    "- Generally longer than Austen's sentences\n",
    "- List-like accumulation within sentences\n",
    "- Emotional intensifiers and repetition\n",
    "- More paratactic (coordinate) structures\n",
    "- Occasional sentence fragments for dramatic effect\n",
    "\"\"\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab49d15f",
   "metadata": {},
   "source": [
    "## Test Generation\n",
    "\n",
    "First, test that the API calls and segmentation work correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "290328fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Class 2 generation...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1404 words\n",
      "Segmented into 8 paragraphs\n",
      "\n",
      "First paragraph:\n",
      "The chipped porcelain felt cool against my palm, the Earl Grey lukewarm. Old Man Hemlock always brewed it too weak, but it was the ritual that mattered—sitting in his cluttered bookshop, pretending to browse while really just absorbing the quiet. Outside, New Birmingham throbbed, a mechanical heart beating faster with every new factory, every new arrival. Inside, Hemlock’s smelled of dust and forgotten things, a refuge. I wasn’t supposed to *be* here, not really. Not Beatrice Ainsworth, daughter of Councillor Ainsworth, destined for a suitable marriage and a life of charitable works and polite conversation. I was supposed to be practicing my pianoforte, or embroidering, or at the very least, accepting a call from young Mr. Finch-Hatton. Instead, I was inhaling the scent of decaying paper and trying to decipher the meaning of a faded etching of a woman sketching wildflowers. “Lost in thought, Miss Ainsworth?” Hemlock’s voice, raspy as dry leaves, startled me. He hadn’t even looked up from his mending. “Just…admiring the print, Mr. Hemlock.” A lie, of course. I hadn’t even noticed it until he mentioned it. He chuckled, a dry, rattling sound. “Admiring, or escaping?”\n",
      "\n",
      "Semicolons: 0, Em-dashes: 1\n"
     ]
    }
   ],
   "source": [
    "# Test generation with a single story\n",
    "print(\"\\nTesting Class 2 generation...\")\n",
    "test_prompt, _ = build_class2_story_prompt_improved(topics)\n",
    "test_story = call_gemma_api_story(test_prompt, generation_type=\"neutral\")\n",
    "\n",
    "if test_story:\n",
    "    print(f\"Generated {len(test_story.split())} words\")\n",
    "    segments = segment_story_improved(test_story)\n",
    "    print(f\"Segmented into {len(segments)} paragraphs\")\n",
    "    print(\"\\nFirst paragraph:\")\n",
    "    print(segments[0])\n",
    "    print(f\"\\nSemicolons: {segments[0].count(';')}, Em-dashes: {segments[0].count('—')}\")\n",
    "else:\n",
    "    print(\"Failed - check API key and quota\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed47bb1d",
   "metadata": {},
   "source": [
    "## Class 2 Generation (Neutral Style)\n",
    "\n",
    "Generate 500 paragraphs using neutral story prompts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac17c25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Class 2 full generation...\n",
      "Story 1: added 9 paragraphs (total: 9/500)\n",
      "Story 2: added 9 paragraphs (total: 18/500)\n",
      "Story 3: added 8 paragraphs (total: 26/500)\n",
      "Story 4: added 8 paragraphs (total: 34/500)\n",
      "Story 5: added 7 paragraphs (total: 41/500)\n",
      "Story 6: added 9 paragraphs (total: 50/500)\n",
      "Story 7: added 7 paragraphs (total: 57/500)\n",
      "Story 8: added 8 paragraphs (total: 65/500)\n",
      "Story 9: added 9 paragraphs (total: 74/500)\n",
      "Story 10: added 9 paragraphs (total: 83/500)\n",
      "Story 11: added 8 paragraphs (total: 91/500)\n",
      "Story 12: added 8 paragraphs (total: 99/500)\n",
      "Story 13: added 7 paragraphs (total: 106/500)\n",
      "Story 14: added 7 paragraphs (total: 113/500)\n",
      "Story 15: added 8 paragraphs (total: 121/500)\n",
      "Story 16: added 8 paragraphs (total: 129/500)\n",
      "Story 17: added 8 paragraphs (total: 137/500)\n",
      "Story 18: added 9 paragraphs (total: 146/500)\n",
      "Story 19: added 8 paragraphs (total: 154/500)\n",
      "Story 20: added 8 paragraphs (total: 162/500)\n",
      "Story 21: added 8 paragraphs (total: 170/500)\n",
      "Story 22: added 8 paragraphs (total: 178/500)\n",
      "Story 23: added 8 paragraphs (total: 186/500)\n",
      "Story 24: added 9 paragraphs (total: 195/500)\n",
      "Story 25: added 7 paragraphs (total: 202/500)\n",
      "Story 26: added 7 paragraphs (total: 209/500)\n",
      "Story 27: added 9 paragraphs (total: 218/500)\n",
      "Story 28: added 8 paragraphs (total: 226/500)\n",
      "Story 29: added 8 paragraphs (total: 234/500)\n",
      "Story 30: added 7 paragraphs (total: 241/500)\n",
      "Story 31: added 8 paragraphs (total: 249/500)\n",
      "Story 32: added 8 paragraphs (total: 257/500)\n",
      "Story 33: added 8 paragraphs (total: 265/500)\n",
      "Story 34: added 7 paragraphs (total: 272/500)\n",
      "Story 35: added 10 paragraphs (total: 282/500)\n",
      "Story 36: added 9 paragraphs (total: 291/500)\n",
      "Story 37: added 8 paragraphs (total: 299/500)\n",
      "Story 38: added 7 paragraphs (total: 306/500)\n",
      "Story 39: added 8 paragraphs (total: 314/500)\n",
      "Story 40: added 8 paragraphs (total: 322/500)\n",
      "Story 41: added 8 paragraphs (total: 330/500)\n",
      "Story 42: added 8 paragraphs (total: 338/500)\n",
      "Story 43: added 8 paragraphs (total: 346/500)\n",
      "Story 44: added 8 paragraphs (total: 354/500)\n",
      "Story 45: added 8 paragraphs (total: 362/500)\n",
      "Story 46: added 9 paragraphs (total: 371/500)\n",
      "Story 47: added 8 paragraphs (total: 379/500)\n",
      "Story 48: added 8 paragraphs (total: 387/500)\n",
      "Story 49: added 8 paragraphs (total: 395/500)\n",
      "Story 50: added 8 paragraphs (total: 403/500)\n",
      "Story 51: added 8 paragraphs (total: 411/500)\n",
      "Story 52: added 7 paragraphs (total: 418/500)\n",
      "Story 53: added 8 paragraphs (total: 426/500)\n",
      "Story 54: added 10 paragraphs (total: 436/500)\n",
      "Story 55: added 8 paragraphs (total: 444/500)\n",
      "Story 56: added 9 paragraphs (total: 453/500)\n",
      "Story 57: added 8 paragraphs (total: 461/500)\n",
      "Story 58: added 7 paragraphs (total: 468/500)\n",
      "Story 59: added 8 paragraphs (total: 476/500)\n",
      "Story 60: added 8 paragraphs (total: 484/500)\n",
      "Story 61: added 7 paragraphs (total: 491/500)\n",
      "Story 62: added 8 paragraphs (total: 499/500)\n",
      "Story 63: added 1 paragraphs (total: 500/500)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStarting Class 2 full generation...\")\n",
    "\n",
    "class2_paragraphs = []\n",
    "seen_hashes = set()\n",
    "stories_generated = 0\n",
    "\n",
    "while len(class2_paragraphs) < 500:\n",
    "    prompt, vid = build_class2_story_prompt_improved(topics)\n",
    "    story = call_gemma_api_story(prompt, generation_type=\"neutral\")\n",
    "    \n",
    "    if not story:\n",
    "        print(\"Story generation failed, retrying...\")\n",
    "        time.sleep(2)\n",
    "        continue\n",
    "    \n",
    "    stories_generated += 1\n",
    "    paragraphs = segment_story_improved(story)\n",
    "    \n",
    "    added = 0\n",
    "    for para in paragraphs:\n",
    "        if len(class2_paragraphs) >= 500:\n",
    "            break\n",
    "        \n",
    "        para_hash = hash(para[:500])\n",
    "        if para_hash in seen_hashes:\n",
    "            continue\n",
    "        \n",
    "        seen_hashes.add(para_hash)\n",
    "        class2_paragraphs.append({\n",
    "            \"text\": para,\n",
    "            \"label\": \"ai\",\n",
    "            \"variant\": \"story\",\n",
    "            \"story_id\": stories_generated,\n",
    "            \"variation_id\": vid\n",
    "        })\n",
    "        added += 1\n",
    "    \n",
    "    print(f\"Story {stories_generated}: added {added} paragraphs (total: {len(class2_paragraphs)}/500)\")\n",
    "    \n",
    "    with open(\"class2_ai_story_paragraphs_try3.json\", \"w\") as f:\n",
    "        json.dump(class2_paragraphs, f, indent=2)\n",
    "    \n",
    "    time.sleep(1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5b3ccad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Class 3 full generation...\n",
      "\n",
      "Generating for AUSTEN (target: 250)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'Title'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mGenerating for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mauthor.upper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (target: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparagraphs_per_author\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m author_count < paragraphs_per_author:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     prompt, vid = \u001b[43mbuild_class3_story_prompt_improved\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhuman_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     story = call_gemma_api_story(prompt, generation_type=\u001b[33m\"\u001b[39m\u001b[33mstyled\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m story:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mbuild_class3_story_prompt_improved\u001b[39m\u001b[34m(topics, author, human_data)\u001b[39m\n\u001b[32m     10\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i, passage \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(passages, \u001b[32m1\u001b[39m):\n\u001b[32m     11\u001b[39m             examples_text += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExample \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mpassage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     13\u001b[39m     prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33mYou are writing a narrative in the authentic style of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mauthor.title()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\n\u001b[32m     14\u001b[39m \n\u001b[32m     15\u001b[39m \u001b[38;5;132;01m{\u001b[39;00mexamples_text\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m     16\u001b[39m \n\u001b[32m     17\u001b[39m \u001b[33mNow write a NEW, ORIGINAL fictional narrative of approximately 1,500-2,000 words.\u001b[39m\n\u001b[32m     18\u001b[39m \n\u001b[32m     19\u001b[39m \u001b[33mThe story should naturally explore these themes:\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;132;01m{\u001b[39;00mtheme_block\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m     21\u001b[39m \n\u001b[32m     22\u001b[39m \u001b[33mSTYLE GUIDE for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mauthor.upper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;132;01m{\u001b[39;00mAUTHOR_STYLE_GUIDES_ENHANCED[author]\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m     24\u001b[39m \n\u001b[32m     25\u001b[39m \u001b[33mIMPORTANT INSTRUCTIONS:\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[33m1. Write AS IF you ARE \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mauthor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTitle\u001b[49m()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m writing a story\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[33m2. Match their sentence structures, rhythms, and patterns (see examples above)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[33m3. Use their characteristic vocabulary and register\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[33m4. Follow their punctuation habits\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[33m5. Adopt their narrative perspective and tone\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[33m6. Let themes emerge through character and situation\u001b[39m\n\u001b[32m     32\u001b[39m \n\u001b[32m     33\u001b[39m \u001b[33mDO NOT:\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[33m- Copy or paraphrase the examples above\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[33m- Reference specific characters, places, or plots from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mauthor\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33ms actual works\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[33m- Break character into modern internet-speak or contemporary slang\u001b[39m\n\u001b[32m     37\u001b[39m \n\u001b[32m     38\u001b[39m \u001b[33mAllow the story to develop organically with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mauthor\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33ms characteristic style—including any stylistic inconsistencies, emotional tangents, or pacing variations that appear in their work.\u001b[39m\n\u001b[32m     39\u001b[39m \n\u001b[32m     40\u001b[39m \u001b[33mWrite only the story. No title, no preamble, no explanation.\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m prompt.strip(), vid\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'Title'"
     ]
    }
   ],
   "source": [
    "print(\"\\nStarting Class 3 full generation...\")\n",
    "\n",
    "class3_paragraphs = []\n",
    "seen_hashes = set()\n",
    "stories_generated = 0\n",
    "authors = [\"austen\", \"gaskell\"]\n",
    "paragraphs_per_author = 250\n",
    "\n",
    "for author in authors:\n",
    "    author_count = 0\n",
    "    print(f\"\\nGenerating for {author.upper()} (target: {paragraphs_per_author})\")\n",
    "    \n",
    "    while author_count < paragraphs_per_author:\n",
    "        prompt, vid = build_class3_story_prompt_improved(topics, author, human_data)\n",
    "        story = call_gemma_api_story(prompt, generation_type=\"styled\")\n",
    "        \n",
    "        if not story:\n",
    "            print(\"Story generation failed, retrying...\")\n",
    "            time.sleep(2)\n",
    "            continue\n",
    "        \n",
    "        stories_generated += 1\n",
    "        paragraphs = segment_story_improved(story, min_words=100, max_words=200)\n",
    "        \n",
    "        added = 0\n",
    "        for para in paragraphs:\n",
    "            if author_count >= paragraphs_per_author:\n",
    "                break\n",
    "            \n",
    "            para_hash = hash(para[:500])\n",
    "            if para_hash in seen_hashes:\n",
    "                continue\n",
    "            \n",
    "            seen_hashes.add(para_hash)\n",
    "            class3_paragraphs.append({\n",
    "                \"text\": para,\n",
    "                \"label\": \"ai\",\n",
    "                \"variant\": \"story\",\n",
    "                \"author_style\": author,\n",
    "                \"story_id\": stories_generated,\n",
    "                \"variation_id\": vid\n",
    "            })\n",
    "            author_count += 1\n",
    "            added += 1\n",
    "        \n",
    "        print(f\"Story {stories_generated} ({author}): added {added} paragraphs ({author}: {author_count}/{paragraphs_per_author})\")\n",
    "        \n",
    "        \n",
    "        with open(\"class3_ai_story_paragraphs_try3.json\", \"w\") as f:\n",
    "             json.dump(class3_paragraphs, f, indent=2)\n",
    "        \n",
    "        time.sleep(1.5)\n",
    "\n",
    "# Verification\n",
    "\n",
    "with open(\"class2_ai_story_paragraphs_try3.json\", \"r\") as f:\n",
    "    class3 = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87247cd4",
   "metadata": {},
   "source": [
    "## Done\n",
    "\n",
    "Generated two AI datasets using few-shot style transfer:\n",
    "- `class2_ai_story_paragraphs_try3.json`: 500 AI paragraphs (neutral, improved prompting)\n",
    "- `class3_ai_story_paragraphs_try3.json`: 500 AI paragraphs (styled, with few-shot examples)\n",
    "\n",
    "Class 1 remains the same human text. The key difference from Try 2 is the inclusion of actual author passages as concrete style examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffc5317",
   "metadata": {},
   "source": [
    "### Dataset Summary\n",
    "\n",
    "**Class 1 (Human):**\n",
    "- Same as Try 1 and Try 2: 6 novels (3 Austen + 3 Gaskell)\n",
    "- Processing: HTML cleaning, boilerplate removal, re-chunking\n",
    "- Output: ~4000+ paragraphs, 100-200 words each\n",
    "\n",
    "**Class 2 (AI-Neutral):**\n",
    "- Source: Gemini API (gemma-3-27b-it)\n",
    "- Strategy: Story-level with improved prompting (temp 1.3, top_k 200)\n",
    "- Output: 500 paragraphs, 100-200 words each\n",
    "\n",
    "**Class 3 (AI-Styled):**\n",
    "- Source: Gemini API (gemma-3-27b-it)\n",
    "- Strategy: Story-level + few-shot examples (3 passages per author)\n",
    "- Temperature: 1.4, top_k 250 (highest diversity)\n",
    "- Output: 500 paragraphs, 100-200 words each\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74845c91",
   "metadata": {},
   "source": [
    "### Why This Matters\n",
    "\n",
    "Try 3 tests the hypothesis that concrete examples improve style transfer. By showing the model actual passages from Austen and Gaskell:\n",
    "- Sentence rhythms become more authentic\n",
    "- Vocabulary shifts toward author-typical terms\n",
    "- Punctuation patterns (semicolons, em-dashes) better match human distribution\n",
    "\n",
    "**Trade-off:** Risk of near-verbatim copying. We monitor this via deduplication, but some similarity is expected and desired - that's the point of style mimicry.\n",
    "\n",
    "In Task 2, we'll compare all three variants (try1: paragraph-level, try2: story-level, try3: few-shot) to see which generation strategy produces the most human-like text while maintaining diversity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_env)",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
